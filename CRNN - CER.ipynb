{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T23:52:01.281946Z","iopub.execute_input":"2022-07-25T23:52:01.282298Z","iopub.status.idle":"2022-07-25T23:52:01.288205Z","shell.execute_reply.started":"2022-07-25T23:52:01.282268Z","shell.execute_reply":"2022-07-25T23:52:01.286658Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Import & Prepare Library","metadata":{}},{"cell_type":"code","source":"!pip install fastwer\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2\nimport fastwer #for calculating CER & WER","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:01.346156Z","iopub.execute_input":"2022-07-25T23:52:01.346443Z","iopub.status.idle":"2022-07-25T23:52:10.486714Z","shell.execute_reply.started":"2022-07-25T23:52:01.346417Z","shell.execute_reply":"2022-07-25T23:52:10.485527Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"np.random.seed(63)\ntf.random.set_seed(63)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:10.489724Z","iopub.execute_input":"2022-07-25T23:52:10.490370Z","iopub.status.idle":"2022-07-25T23:52:10.496622Z","shell.execute_reply.started":"2022-07-25T23:52:10.490328Z","shell.execute_reply":"2022-07-25T23:52:10.495308Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"#Loading Data\ntrain=pd.read_csv('../input/handwriting-recognition/written_name_train_v2.csv')\nval=pd.read_csv('../input/handwriting-recognition/written_name_validation_v2.csv')\ntest=pd.read_csv('../input/handwriting-recognition/written_name_test_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:10.498015Z","iopub.execute_input":"2022-07-25T23:52:10.498921Z","iopub.status.idle":"2022-07-25T23:52:10.863368Z","shell.execute_reply.started":"2022-07-25T23:52:10.498881Z","shell.execute_reply":"2022-07-25T23:52:10.862333Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"**Dealing with Missing Value**","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:10.865812Z","iopub.execute_input":"2022-07-25T23:52:10.866190Z","iopub.status.idle":"2022-07-25T23:52:11.198549Z","shell.execute_reply.started":"2022-07-25T23:52:10.866150Z","shell.execute_reply":"2022-07-25T23:52:11.197464Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"val.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.200070Z","iopub.execute_input":"2022-07-25T23:52:11.200535Z","iopub.status.idle":"2022-07-25T23:52:11.253132Z","shell.execute_reply.started":"2022-07-25T23:52:11.200496Z","shell.execute_reply":"2022-07-25T23:52:11.252148Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.254682Z","iopub.execute_input":"2022-07-25T23:52:11.255034Z","iopub.status.idle":"2022-07-25T23:52:11.305109Z","shell.execute_reply.started":"2022-07-25T23:52:11.254998Z","shell.execute_reply":"2022-07-25T23:52:11.304079Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"print(\"Jumlah NAN dalam train set      : \", train['IDENTITY'].isnull().sum())\nprint(\"Jumlah NAN dalam validation set : \", val['IDENTITY'].isnull().sum())\nprint(\"Jumlah NAN dalam validation set : \", test['IDENTITY'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.306737Z","iopub.execute_input":"2022-07-25T23:52:11.307397Z","iopub.status.idle":"2022-07-25T23:52:11.354579Z","shell.execute_reply.started":"2022-07-25T23:52:11.307358Z","shell.execute_reply":"2022-07-25T23:52:11.353553Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#Karena jumlah NA tidak signifikan dibandingkan sample set yang kita miliki,\n#maka kita mengeluarkan variabel yang memiliki missing label\n\ntrain.dropna(inplace=True)\ntrain.reset_index(drop=True, inplace=True)\ntest.dropna(inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.dropna(inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.356151Z","iopub.execute_input":"2022-07-25T23:52:11.356813Z","iopub.status.idle":"2022-07-25T23:52:11.462634Z","shell.execute_reply.started":"2022-07-25T23:52:11.356776Z","shell.execute_reply":"2022-07-25T23:52:11.461627Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"**Dealing with Uppercase & Setting Number of Character**","metadata":{}},{"cell_type":"code","source":"#Count data with missing label\nprint(\"Jumlah Not Capital dalam train set      : \", len(train) - train['IDENTITY'].str.isupper().sum())\nprint(\"Jumlah Not Capital dalam validation set : \", len(val) - val['IDENTITY'].str.isupper().sum())\nprint(\"Jumlah Not Capital dalam test set : \", len(test) - test['IDENTITY'].str.isupper().sum())","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.464184Z","iopub.execute_input":"2022-07-25T23:52:11.464575Z","iopub.status.idle":"2022-07-25T23:52:11.649159Z","shell.execute_reply.started":"2022-07-25T23:52:11.464538Z","shell.execute_reply":"2022-07-25T23:52:11.648125Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#Show image with lower string\ntrain_lower = train[~train['IDENTITY'].str.isupper()]\ntrain_lower.reset_index(inplace = True, drop=True)\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(4):\n    ax = plt.subplot(2, 2, i+1)\n    img_dir = '../input/handwriting-recognition/train_v2/train/'+train_lower.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(test_lower.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:11.653994Z","iopub.execute_input":"2022-07-25T23:52:11.654264Z","iopub.status.idle":"2022-07-25T23:52:12.047419Z","shell.execute_reply.started":"2022-07-25T23:52:11.654240Z","shell.execute_reply":"2022-07-25T23:52:12.046271Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"\n#Terlihat bahwa sebenarnya karakter yang dilabeli dengan \ntrain['Length']=train['IDENTITY'].apply(lambda x : len(str(x)))\nmax_name = 16\nmin_name = 2\ntrain21=train[train['Length']>max_name]\ntrain=train[train['Length']<=max_name]\ntrain=train[train['Length']>=min_name]\ntrain['IDENTITY']=train['IDENTITY'].str.upper()\nval['IDENTITY']=val['IDENTITY'].str.upper()\ntest['IDENTITY']=test['IDENTITY'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:12.048911Z","iopub.execute_input":"2022-07-25T23:52:12.049206Z","iopub.status.idle":"2022-07-25T23:52:12.481227Z","shell.execute_reply.started":"2022-07-25T23:52:12.049173Z","shell.execute_reply":"2022-07-25T23:52:12.480256Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"train21","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:12.484446Z","iopub.execute_input":"2022-07-25T23:52:12.485127Z","iopub.status.idle":"2022-07-25T23:52:12.497499Z","shell.execute_reply.started":"2022-07-25T23:52:12.485087Z","shell.execute_reply":"2022-07-25T23:52:12.496369Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"**Dealing With Unreadable Character**","metadata":{}},{"cell_type":"code","source":"train[train['IDENTITY'] == 'UNREADABLE']","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:12.499472Z","iopub.execute_input":"2022-07-25T23:52:12.499825Z","iopub.status.idle":"2022-07-25T23:52:12.556149Z","shell.execute_reply.started":"2022-07-25T23:52:12.499791Z","shell.execute_reply":"2022-07-25T23:52:12.555291Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"unreadable = train[train['IDENTITY'] == 'UNREADABLE']\nunreadable.reset_index(inplace = True, drop=True)\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '../input/handwriting-recognition/train_v2/train/'+unreadable.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:12.557259Z","iopub.execute_input":"2022-07-25T23:52:12.557636Z","iopub.status.idle":"2022-07-25T23:52:12.941586Z","shell.execute_reply.started":"2022-07-25T23:52:12.557599Z","shell.execute_reply":"2022-07-25T23:52:12.940368Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#Label pada gambar unreadable tidak konsisten\n#Mata manusia masih kesusahan membedakan mana gambar yang seharusnya dilabeli unreadable dan tidak\n#Kami telah mencoba menyusun model untuk memprediksi readability namun performanya kurang bagus\n#Oleh karena itu, kami mengeluarkan gambar dgn label unreadable dari training & validation\n\ntrain = train.loc[(train['IDENTITY'] != 'UNREADABLE')]\nval = val.loc[(val['IDENTITY'] != 'UNREADABLE')]\n# test = train.loc[(train['IDENTITY'] != 'UNREADABLE')]","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:12.943138Z","iopub.execute_input":"2022-07-25T23:52:12.943784Z","iopub.status.idle":"2022-07-25T23:52:13.024716Z","shell.execute_reply.started":"2022-07-25T23:52:12.943738Z","shell.execute_reply":"2022-07-25T23:52:13.023732Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#Dataset yang akan kami gunakan adalah sebanyak 100000 untuk training dan 10000 untuk validation\n#Pertimbangannya, jumlah tersebut telah mencakup variability yang ada di dataset\n\nmax_data_train = 100000\nmax_data_val = 10000\ntrain = train.iloc[:max_data_train]\nval = val.iloc[:max_data_val]","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:13.026108Z","iopub.execute_input":"2022-07-25T23:52:13.026579Z","iopub.status.idle":"2022-07-25T23:52:13.033308Z","shell.execute_reply.started":"2022-07-25T23:52:13.026540Z","shell.execute_reply":"2022-07-25T23:52:13.031533Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"print(f\"Total training samples: {train.shape[0]}\")\nprint(f\"Total validation samples: {val.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:13.034879Z","iopub.execute_input":"2022-07-25T23:52:13.035304Z","iopub.status.idle":"2022-07-25T23:52:13.044705Z","shell.execute_reply.started":"2022-07-25T23:52:13.035268Z","shell.execute_reply":"2022-07-25T23:52:13.043612Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"base_path = '../input/handwriting-recognition'\n\ndef get_image_paths_and_labels(df, status):\n    paths = []\n    corrected_samples = []\n    data_path = os.path.join(base_path, status+'_v2', status)\n    fn=df['FILENAME'].to_numpy()\n    label=df['IDENTITY'].to_numpy()\n    \n    for i in range (len(fn)):\n        img_path = os.path.join(\n            data_path, fn[i]\n        )\n        if os.path.getsize(img_path):\n            paths.append(img_path)\n            corrected_samples.append(label[i])\n            \n    return paths, corrected_samples\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:13.046147Z","iopub.execute_input":"2022-07-25T23:52:13.046723Z","iopub.status.idle":"2022-07-25T23:52:13.055005Z","shell.execute_reply.started":"2022-07-25T23:52:13.046685Z","shell.execute_reply":"2022-07-25T23:52:13.053966Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"train_img_paths, train_labels = get_image_paths_and_labels(train, 'train')\nval_img_paths, val_labels = get_image_paths_and_labels(val, 'validation')\ntest_img_paths, test_labels = get_image_paths_and_labels(test, 'test')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:52:13.056873Z","iopub.execute_input":"2022-07-25T23:52:13.058031Z","iopub.status.idle":"2022-07-25T23:53:18.245344Z","shell.execute_reply.started":"2022-07-25T23:52:13.057995Z","shell.execute_reply":"2022-07-25T23:53:18.244365Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Get vocab of character\ncharacters = set()\n\nfor label in train_labels:\n    for char in label:\n        characters.add(char)\n\ncharacters = sorted(list(characters))\nprint(\"Vocab size: \", len(characters))\nprint(characters)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:18.246930Z","iopub.execute_input":"2022-07-25T23:53:18.247324Z","iopub.status.idle":"2022-07-25T23:53:18.346013Z","shell.execute_reply.started":"2022-07-25T23:53:18.247263Z","shell.execute_reply":"2022-07-25T23:53:18.344966Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Build character vocabulary\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Convert characters to integers.\nchar_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n\n# Convert integers back to original characters.\nnum_to_char = StringLookup(\n    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:18.347399Z","iopub.execute_input":"2022-07-25T23:53:18.348050Z","iopub.status.idle":"2022-07-25T23:53:18.364182Z","shell.execute_reply.started":"2022-07-25T23:53:18.348005Z","shell.execute_reply":"2022-07-25T23:53:18.363354Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def distortion_free_resize(image, img_size):\n    w, h = img_size\n    image = tf.image.resize_with_pad(image, h, w)\n\n    # Check the amount of padding needed to be done.\n#     pad_height = h - tf.shape(image)[0]\n#     pad_width = w - tf.shape(image)[1]\n\n    image = tf.transpose(image, perm=[1, 0, 2])\n    image = tf.image.flip_left_right(image)\n    return image\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:18.367071Z","iopub.execute_input":"2022-07-25T23:53:18.367398Z","iopub.status.idle":"2022-07-25T23:53:18.375530Z","shell.execute_reply.started":"2022-07-25T23:53:18.367368Z","shell.execute_reply":"2022-07-25T23:53:18.374603Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# Data Pipeline","metadata":{}},{"cell_type":"code","source":"batch_size = 64\npadding_token = 99\nimage_width = 256\nimage_height = 64\nmax_len = 32\n\n\ndef preprocess_image(image_path, img_size=(image_width, image_height)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, 1)\n    image = distortion_free_resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n\ndef vectorize_label(label):\n    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n    length = tf.shape(label)[0]\n    pad_amount = max_len - length\n    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n    return label\n\n\ndef process_images_labels(image_path, label):\n    image = preprocess_image(image_path)\n    label = vectorize_label(label)\n    return {\"image\": image, \"label\": label}\n\n\ndef prepare_dataset(image_paths, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n        process_images_labels, num_parallel_calls=AUTOTUNE\n    )\n    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:18.377293Z","iopub.execute_input":"2022-07-25T23:53:18.378129Z","iopub.status.idle":"2022-07-25T23:53:18.394943Z","shell.execute_reply.started":"2022-07-25T23:53:18.378042Z","shell.execute_reply":"2022-07-25T23:53:18.393991Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"train_ds = prepare_dataset(train_img_paths, train_labels)\nval_ds = prepare_dataset(val_img_paths, val_labels)\ntest_ds = prepare_dataset(test_img_paths, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:18.396605Z","iopub.execute_input":"2022-07-25T23:53:18.397020Z","iopub.status.idle":"2022-07-25T23:53:19.784646Z","shell.execute_reply.started":"2022-07-25T23:53:18.396982Z","shell.execute_reply":"2022-07-25T23:53:19.783638Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:19.788304Z","iopub.execute_input":"2022-07-25T23:53:19.788617Z","iopub.status.idle":"2022-07-25T23:53:19.796710Z","shell.execute_reply.started":"2022-07-25T23:53:19.788592Z","shell.execute_reply":"2022-07-25T23:53:19.795026Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"for data in train_ds.take(1):\n    images, labels = data[\"image\"], data[\"label\"]\n\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    for i in range(16):\n        img = images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        # Gather indices where label!= padding_token.\n        label = labels[i]\n        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n        # Convert to string.\n        label = tf.strings.reduce_join(num_to_char(indices))\n        label = label.numpy().decode(\"utf-8\")\n\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(label)\n        ax[i // 4, i % 4].axis(\"off\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:19.798189Z","iopub.execute_input":"2022-07-25T23:53:19.798789Z","iopub.status.idle":"2022-07-25T23:53:20.654137Z","shell.execute_reply.started":"2022-07-25T23:53:19.798752Z","shell.execute_reply":"2022-07-25T23:53:20.653241Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"val_images = []\nval_labels = []\n\nfor batch in val_ds:\n    val_images.append(batch[\"image\"])\n    val_labels.append(batch[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:20.655520Z","iopub.execute_input":"2022-07-25T23:53:20.656487Z","iopub.status.idle":"2022-07-25T23:53:26.430849Z","shell.execute_reply.started":"2022-07-25T23:53:20.656450Z","shell.execute_reply":"2022-07-25T23:53:26.429795Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"#val_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:26.438426Z","iopub.execute_input":"2022-07-25T23:53:26.438707Z","iopub.status.idle":"2022-07-25T23:53:26.443027Z","shell.execute_reply.started":"2022-07-25T23:53:26.438681Z","shell.execute_reply":"2022-07-25T23:53:26.441984Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"\ndef calculate_edit_distance(labels, predictions):\n    # Get a single batch and convert its labels to sparse tensors.\n    sparse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n\n    # Make predictions and convert them to sparse tensors.\n    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n    predictions_decoded = keras.backend.ctc_decode(\n        predictions, input_length=input_len, greedy=True\n    )[0][0][:, :max_len]\n    sparse_predictions = tf.cast(\n        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n    )\n\n    # Compute individual edit distances and average them out.\n    edit_distances = tf.edit_distance(\n        sparse_predictions, sparse_labels, normalize=False\n    )\n    return tf.reduce_mean(edit_distances)\n\n\nclass EditDistanceCallback(keras.callbacks.Callback):\n    def __init__(self, pred_model):\n        super().__init__()\n        self.prediction_model = pred_model\n\n    def on_epoch_end(self, epoch, logs=None):\n        edit_distances = []\n\n        for i in range(len(val_images)):\n            labels = val_labels[i]\n            predictions = self.prediction_model.predict(val_images[i])\n            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n\n        print(\n            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n        )\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:26.444947Z","iopub.execute_input":"2022-07-25T23:53:26.445758Z","iopub.status.idle":"2022-07-25T23:53:26.457901Z","shell.execute_reply.started":"2022-07-25T23:53:26.445674Z","shell.execute_reply":"2022-07-25T23:53:26.457014Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# **Model I**:\nDalam percobaan model pertama kami menggunakan 2 layer CNN, 1 layer dense, 2 layer LSTM, dan layer CTC.\nModel ini terinspirasi dari dokumentasi keras.","metadata":{}},{"cell_type":"code","source":"class CTCLayer(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        return y_pred\n\n\ndef build_model1():\n    # Inputs Model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First CNN\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    \n    \n    # Second CNN.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    \n\n    #CNN di layer terakhir menghasilkan 64 fitur\n    #Maxpooling 2x2 dua kali -> ukuran berkurang sebanyak 1/4\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n\n    #First RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n    )(x)\n    \n    #Second RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    #Softmax Layers\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    #CTC Layer\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    #Mendefinisikan Model\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    #Optimization.\n    opt = keras.optimizers.Adam()\n    #Mengcompile Model\n    model.compile(optimizer=opt)\n    return model\n\n\n# Menginisiasi Model\nmodel1 = build_model1()\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:56:36.668879Z","iopub.execute_input":"2022-07-25T23:56:36.669230Z","iopub.status.idle":"2022-07-25T23:56:37.607375Z","shell.execute_reply.started":"2022-07-25T23:56:36.669198Z","shell.execute_reply":"2022-07-25T23:56:37.606363Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nmodel1 = build_model1()\nprediction_model1 = keras.models.Model(\n    model1.get_layer(name=\"image\").input, model1.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model1)\n\n#Train the model.\nhistory = model1.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    callbacks=[edit_distance_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:57:49.235462Z","iopub.execute_input":"2022-07-25T23:57:49.235915Z","iopub.status.idle":"2022-07-26T00:23:11.551989Z","shell.execute_reply.started":"2022-07-25T23:57:49.235867Z","shell.execute_reply":"2022-07-26T00:23:11.550978Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:23:11.554273Z","iopub.execute_input":"2022-07-26T00:23:11.554649Z","iopub.status.idle":"2022-07-26T00:23:11.560957Z","shell.execute_reply.started":"2022-07-26T00:23:11.554612Z","shell.execute_reply":"2022-07-26T00:23:11.559742Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"**Showing The Results of Model I**","metadata":{}},{"cell_type":"code","source":"def decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\nfor batch in test_ds.take(1):\n    batch_images = batch[\"image\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model1.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:26:21.891110Z","iopub.execute_input":"2022-07-26T00:26:21.891616Z","iopub.status.idle":"2022-07-26T00:26:25.175549Z","shell.execute_reply.started":"2022-07-26T00:26:21.891564Z","shell.execute_reply":"2022-07-26T00:26:25.174361Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"**Model I Performance on Train Dataset**","metadata":{}},{"cell_type":"code","source":"train[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 100\nfor batch in train_ds.take(number_of_batches):\n    batch_images = batch[\"image\"]\n    preds = prediction_model1.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    train.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntrain_output = train[:batch_size*number_of_batches]\ntrain_output[\"CER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntrain_output[\"WER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(train_output)\nprint(\"CER_train_average: \", train_output[\"CER\"].mean())\nprint(\"WER_train_average: \", train_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:26:36.555015Z","iopub.execute_input":"2022-07-26T00:26:36.555407Z","iopub.status.idle":"2022-07-26T00:26:50.580607Z","shell.execute_reply.started":"2022-07-26T00:26:36.555374Z","shell.execute_reply":"2022-07-26T00:26:50.579392Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"**Model I Performance on Validation Dataset**","metadata":{}},{"cell_type":"code","source":"val[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in val_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model1.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    val.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\nval_output = val[:batch_size*number_of_batches]\nval_output[\"CER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\nval_output[\"WER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(val_output)\nprint(\"CER_val_average: \", val_output[\"CER\"].mean())\nprint(\"WER_val_average: \", val_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:26:55.409989Z","iopub.execute_input":"2022-07-26T00:26:55.410386Z","iopub.status.idle":"2022-07-26T00:27:02.495799Z","shell.execute_reply.started":"2022-07-26T00:26:55.410349Z","shell.execute_reply":"2022-07-26T00:27:02.494657Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"**Penentuan Single Evaluation Metrics:**\nSebelum melakukan model tuning, kami menentukan single evaluation metrics yang akan digunakan untuk model kami.\nBerdasarkan berbagai literatur, CER & WER paling banyak digunakan untuk text recognition, dimana CER digunakan untuk menilai model dengan jumlah karakter sedikit, sedangkan WER digunakan untuk tulisan yang mengandung banyak kata2 (Panjang).\nKarena model ini memprediksi jumlah karakter yang rata-rata jumlahnya kurang dari 20 karakter, maka kami akan menggunakan CER sebagai single evaluation Metrics.\n\n**Penentuan Unreducable Bias:**\nSebelum melakukan analisis terhadap model, kami menentukan unreducable Bias terlebih dahulu. Kami melakukan pengecekan terhadap 300 gambar, dan didapat bahwa rata-rata terdapat 2-3 gambar yang unreadable. Oleh karena itu, kita menentukan unreadable bias sebanyak 1%.\n\n**Performance Model I Analysis:**\nKami akan menggunakan teknik Orthogonalization untuk melakukan tuning pada model. Model I memiliki CER pada training sebesar 6.1% dan CER pada validation sebesar 6.8%. Selisih error pada training dan unreducable bias menandakan bahwa model masih mengalami underfitting. Oleh karena itu, kami akan fokus membenahi masalah underfitting terlebih dahulu.\n\n","metadata":{}},{"cell_type":"markdown","source":"# **Model II**\nkarena model I masih memiliki masalah underfitting, kami akan mencoba mengatasi masalah underfitting tersebut dengan menambah CNN layer menjadi 4 layer, dan dense layer menjadi 2 layer, dan menambah epoch menjadi 25","metadata":{}},{"cell_type":"code","source":"class CTCLayer(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        return y_pred\n\n\ndef build_model2():\n    # Inputs Model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First CNN\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    \n    # Second CNN.\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    \n    # Third CNN.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv3\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    \n    # Fourth CNN.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv4\",\n    )(x)\n    \n    #CNN di layer terakhir menghasilkan 64 fitur\n    #Maxpooling 2x2 dua kali -> ukuran berkurang sebanyak 1/4\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(256, activation=\"relu\", name=\"dense3\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n\n    #First RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n    )(x)\n    \n    #Second RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    #Softmax Layers\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    #CTC Layer\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    #Mendefinisikan Model\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    #Optimization.\n    opt = keras.optimizers.Adam()\n    #Mengcompile Model\n    model.compile(optimizer=opt)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:28:20.246206Z","iopub.execute_input":"2022-07-26T00:28:20.246676Z","iopub.status.idle":"2022-07-26T00:28:20.285396Z","shell.execute_reply.started":"2022-07-26T00:28:20.246640Z","shell.execute_reply":"2022-07-26T00:28:20.283840Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# Menginisiasi Model\nmodel2 = build_model2()\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:28:29.888566Z","iopub.execute_input":"2022-07-26T00:28:29.888990Z","iopub.status.idle":"2022-07-26T00:28:30.950839Z","shell.execute_reply.started":"2022-07-26T00:28:29.888955Z","shell.execute_reply":"2022-07-26T00:28:30.948840Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"epochs = 25\nmodel2 = build_model2()\nprediction_model2 = keras.models.Model(\n    model2.get_layer(name=\"image\").input, model2.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model2)\n\n#Train the model.\nhistory = model2.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    callbacks=[edit_distance_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T00:37:06.990233Z","iopub.execute_input":"2022-07-26T00:37:06.991144Z","iopub.status.idle":"2022-07-26T01:46:35.054380Z","shell.execute_reply.started":"2022-07-26T00:37:06.991096Z","shell.execute_reply":"2022-07-26T01:46:35.053387Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"def decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\nfor batch in test_ds.take(1):\n    batch_images = batch[\"image\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model2.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T01:59:09.854228Z","iopub.execute_input":"2022-07-26T01:59:09.854857Z","iopub.status.idle":"2022-07-26T01:59:11.156500Z","shell.execute_reply.started":"2022-07-26T01:59:09.854822Z","shell.execute_reply":"2022-07-26T01:59:11.155473Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"**Model II Performance on Train Dataset**","metadata":{}},{"cell_type":"code","source":"train[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 100\nfor batch in train_ds.take(number_of_batches):\n    batch_images = batch[\"image\"]\n    preds = prediction_model2.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    train.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntrain_output = train[:batch_size*number_of_batches]\ntrain_output[\"CER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntrain_output[\"WER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(train_output)\nprint(\"CER_train_average: \", train_output[\"CER\"].mean())\nprint(\"WER_train_average: \", train_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T01:47:33.214022Z","iopub.execute_input":"2022-07-26T01:47:33.214746Z","iopub.status.idle":"2022-07-26T01:47:47.268929Z","shell.execute_reply.started":"2022-07-26T01:47:33.214686Z","shell.execute_reply":"2022-07-26T01:47:47.267797Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"**Model II Performance on Validation Dataset**","metadata":{}},{"cell_type":"code","source":"val[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in val_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model2.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    val.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\nval_output = val[:batch_size*number_of_batches]\nval_output[\"CER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\nval_output[\"WER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(val_output)\nprint(\"CER_val_average: \", val_output[\"CER\"].mean())\nprint(\"WER_val_average: \", val_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T01:47:09.398198Z","iopub.execute_input":"2022-07-26T01:47:09.398680Z","iopub.status.idle":"2022-07-26T01:47:16.397702Z","shell.execute_reply.started":"2022-07-26T01:47:09.398625Z","shell.execute_reply":"2022-07-26T01:47:16.396626Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"**Analisis:**\nBerdasarkan performa Model II, kita dapat melihat bahwa model II mampu meingkatkan CER pada training dataset menjadi sebesar 2.93%. Namun, performa pada validation dataset CERnya masih di angka 5.67. Hal ini mengindikasikan bahwa model memiliki masalah overfitting. Oleh karena itu, pada model selanjutnya kita akan berfokus menangani masalah underfitting tersebut","metadata":{}},{"cell_type":"markdown","source":"# **Model III**\nPada model ini, kita akan mengurangi masalah overfitting dengan menambahkan layer drop out.","metadata":{}},{"cell_type":"code","source":"\nclass CTCLayer(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        return y_pred\n\n\ndef build_model():\n    # Inputs Model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First CNN\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    \n    # Second CNN.\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    # Third CNN.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv3\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    \n    # Fourth CNN.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv4\",\n    )(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    #CNN di layer terakhir menghasilkan 64 fitur\n    #Maxpooling 2x2 dua kali -> ukuran berkurang sebanyak 1/4\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(256, activation=\"relu\", name=\"dense3\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n\n    #First RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n    )(x)\n    \n    #Second RNN\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    #Softmax Layers\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    #CTC Layer\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    #Mendefinisikan Model\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    #Optimization.\n    opt = keras.optimizers.Adam()\n    #Mengcompile Model\n    model.compile(optimizer=opt)\n    return model\n\n\n# Menginisiasi Model\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T03:15:47.986110Z","iopub.execute_input":"2022-07-26T03:15:47.986510Z","iopub.status.idle":"2022-07-26T03:15:49.127373Z","shell.execute_reply.started":"2022-07-26T03:15:47.986480Z","shell.execute_reply":"2022-07-26T03:15:49.126051Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"epochs = 25\nmodel = build_model()\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model)\n\n#Train the model.\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    callbacks=[edit_distance_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T03:15:56.320941Z","iopub.execute_input":"2022-07-26T03:15:56.321281Z","iopub.status.idle":"2022-07-26T04:27:21.969576Z","shell.execute_reply.started":"2022-07-26T03:15:56.321251Z","shell.execute_reply":"2022-07-26T04:27:21.968480Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"#Add 5 epoch.\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=5,\n    callbacks=[edit_distance_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:29:24.149371Z","iopub.execute_input":"2022-07-26T04:29:24.150357Z","iopub.status.idle":"2022-07-26T04:44:39.992657Z","shell.execute_reply.started":"2022-07-26T04:29:24.150286Z","shell.execute_reply":"2022-07-26T04:44:39.991293Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"model.save(\"my_model_v3.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T23:53:26.586299Z","iopub.status.idle":"2022-07-25T23:53:26.587066Z","shell.execute_reply.started":"2022-07-25T23:53:26.586815Z","shell.execute_reply":"2022-07-25T23:53:26.586838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Showing The Results of Model III**","metadata":{}},{"cell_type":"code","source":"def decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\nfor batch in test_ds.take(2):\n    batch_images = batch[\"image\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T05:05:15.754392Z","iopub.execute_input":"2022-07-26T05:05:15.755103Z","iopub.status.idle":"2022-07-26T05:05:17.794439Z","shell.execute_reply.started":"2022-07-26T05:05:15.755068Z","shell.execute_reply":"2022-07-26T05:05:17.793295Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance","metadata":{}},{"cell_type":"markdown","source":"**Model Performance on Train Dataset**","metadata":{}},{"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:44:49.586374Z","iopub.execute_input":"2022-07-26T04:44:49.587084Z","iopub.status.idle":"2022-07-26T04:44:49.593156Z","shell.execute_reply.started":"2022-07-26T04:44:49.587042Z","shell.execute_reply":"2022-07-26T04:44:49.591950Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"train[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 100\nfor batch in train_ds.take(number_of_batches):\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    train.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntrain_output = train[:batch_size*number_of_batches]\ntrain_output[\"CER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntrain_output[\"WER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(train_output)\nprint(\"CER_train_average: \", train_output[\"CER\"].mean())\nprint(\"WER_train_average: \", train_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:46:12.727852Z","iopub.execute_input":"2022-07-26T04:46:12.728638Z","iopub.status.idle":"2022-07-26T04:46:27.812993Z","shell.execute_reply.started":"2022-07-26T04:46:12.728595Z","shell.execute_reply":"2022-07-26T04:46:27.811709Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"**Model Performance on Validation Dataset**","metadata":{}},{"cell_type":"code","source":"val[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in val_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    val.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\nval_output = val[:batch_size*number_of_batches]\nval_output[\"CER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\nval_output[\"WER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(val_output)\nprint(\"CER_test_average: \", val_output[\"CER\"].mean())\nprint(\"WER_test_average: \", val_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:45:32.395862Z","iopub.execute_input":"2022-07-26T04:45:32.396237Z","iopub.status.idle":"2022-07-26T04:45:39.637649Z","shell.execute_reply.started":"2022-07-26T04:45:32.396206Z","shell.execute_reply":"2022-07-26T04:45:39.636524Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"markdown","source":"**Model Performance on Test Dataset**","metadata":{}},{"cell_type":"code","source":"test[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in test_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    test.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntest_output = test[:batch_size*number_of_batches]\ntest_output[\"CER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntest_output[\"WER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(test_output)\nprint(\"CER_test_average: \", test_output[\"CER\"].mean())\nprint(\"WER_test_average: \", test_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:46:27.814673Z","iopub.execute_input":"2022-07-26T04:46:27.816030Z","iopub.status.idle":"2022-07-26T04:46:36.373030Z","shell.execute_reply.started":"2022-07-26T04:46:27.815988Z","shell.execute_reply":"2022-07-26T04:46:36.371770Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"**Analisis:**\nBerdasarkan hasil di atas, memiliki CER sebanyak 3% untuk training set dan sekitar 4% untuk validation dan testing set. Standar OCR yang bagus adalah sekitar 1-2%, rata-rata sekitar 2-10%, dan kurang apabila lebih dari 10%. Mengingat OCR ini melibatkan karakter tulisan tangan yang kadang susah dikenali bahkan oleh manusia, maka kami merasa error rate tersebut dapat diterima dan siap di deploy.","metadata":{}},{"cell_type":"markdown","source":"# Error Analysis","metadata":{}},{"cell_type":"code","source":"#rank the highest error\ntest_highest_error = test_output.sort_values(by=\"CER\", ascending = False)\ntest_highest_error.reset_index(drop=True, inplace=True)\ntest_highest_error.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T04:47:07.435755Z","iopub.execute_input":"2022-07-26T04:47:07.436527Z","iopub.status.idle":"2022-07-26T04:47:07.468467Z","shell.execute_reply.started":"2022-07-26T04:47:07.436478Z","shell.execute_reply":"2022-07-26T04:47:07.467111Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 20))\n\nfor i in range(18):\n    ax = plt.subplot(6, 3, i+1)\n    img_dir = '../input/handwriting-recognition/test_v2/test/'+test_highest_error.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(test_highest_error.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T05:00:24.323250Z","iopub.execute_input":"2022-07-26T05:00:24.324257Z","iopub.status.idle":"2022-07-26T05:00:25.186457Z","shell.execute_reply.started":"2022-07-26T05:00:24.324210Z","shell.execute_reply":"2022-07-26T05:00:25.185363Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":"**Analisis:**\nTerlihat bahwa kebanyakan gambar yang salah terprediksi dengan nilai CER besar karena memang tulisan tersebut sulit dibaca oleh mata manusia atau karena gambar tersebut terjadi kesalahan dalam pelabelan","metadata":{}}]}