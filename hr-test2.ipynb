{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastwer\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2\n\nimport fastwer #for calculating CER & WER","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:14.369330Z","iopub.execute_input":"2022-07-24T14:49:14.369677Z","iopub.status.idle":"2022-07-24T14:49:23.794484Z","shell.execute_reply.started":"2022-07-24T14:49:14.369650Z","shell.execute_reply":"2022-07-24T14:49:23.793369Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"np.random.seed(63)\ntf.random.set_seed(63)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:23.797724Z","iopub.execute_input":"2022-07-24T14:49:23.798094Z","iopub.status.idle":"2022-07-24T14:49:23.805185Z","shell.execute_reply.started":"2022-07-24T14:49:23.798055Z","shell.execute_reply":"2022-07-24T14:49:23.804290Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/handwriting-recognition/written_name_train_v2.csv')\nval=pd.read_csv('../input/handwriting-recognition/written_name_validation_v2.csv')\ntest=pd.read_csv('../input/handwriting-recognition/written_name_test_v2.csv')\n\ntrain.dropna(inplace=True)\ntrain.reset_index(drop=True, inplace=True)\ntest.dropna(inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.dropna(inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:23.806993Z","iopub.execute_input":"2022-07-24T14:49:23.807887Z","iopub.status.idle":"2022-07-24T14:49:24.418988Z","shell.execute_reply.started":"2022-07-24T14:49:23.807848Z","shell.execute_reply":"2022-07-24T14:49:24.418047Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train['Length']=train['IDENTITY'].apply(lambda x : len(str(x)))\nmax_name = 16\nmin_name = 2\ntrain21=train[train['Length']>max_name]\ntrain=train[train['Length']<=max_name]\ntrain=train[train['Length']>=min_name]\ntrain['IDENTITY']=train['IDENTITY'].str.upper()\n\nval['IDENTITY']=val['IDENTITY'].str.upper()\ntest['IDENTITY']=test['IDENTITY'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:24.421664Z","iopub.execute_input":"2022-07-24T14:49:24.422335Z","iopub.status.idle":"2022-07-24T14:49:24.879366Z","shell.execute_reply.started":"2022-07-24T14:49:24.422296Z","shell.execute_reply":"2022-07-24T14:49:24.878409Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train21","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:24.880857Z","iopub.execute_input":"2022-07-24T14:49:24.881262Z","iopub.status.idle":"2022-07-24T14:49:24.901958Z","shell.execute_reply.started":"2022-07-24T14:49:24.881227Z","shell.execute_reply":"2022-07-24T14:49:24.901165Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train[train['IDENTITY'] == 'UNREADABLE']","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:24.903384Z","iopub.execute_input":"2022-07-24T14:49:24.903713Z","iopub.status.idle":"2022-07-24T14:49:24.958545Z","shell.execute_reply.started":"2022-07-24T14:49:24.903680Z","shell.execute_reply":"2022-07-24T14:49:24.957388Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train = train.loc[(train['IDENTITY'] != 'UNREADABLE')]\nval = val.loc[(val['IDENTITY'] != 'UNREADABLE')]\n#test = train.loc[(train['IDENTITY'] != 'UNREADABLE')]","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:24.960293Z","iopub.execute_input":"2022-07-24T14:49:24.960702Z","iopub.status.idle":"2022-07-24T14:49:25.033758Z","shell.execute_reply.started":"2022-07-24T14:49:24.960663Z","shell.execute_reply":"2022-07-24T14:49:25.032894Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"max_data_train = 100000\nmax_data_val = 10000\ntrain = train.iloc[:max_data_train]\nval = val.iloc[:max_data_val]","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:25.035034Z","iopub.execute_input":"2022-07-24T14:49:25.035493Z","iopub.status.idle":"2022-07-24T14:49:25.040680Z","shell.execute_reply.started":"2022-07-24T14:49:25.035456Z","shell.execute_reply":"2022-07-24T14:49:25.039643Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f\"Total training samples: {train.shape[0]}\")\nprint(f\"Total validation samples: {val.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:25.041879Z","iopub.execute_input":"2022-07-24T14:49:25.042525Z","iopub.status.idle":"2022-07-24T14:49:25.052339Z","shell.execute_reply.started":"2022-07-24T14:49:25.042490Z","shell.execute_reply":"2022-07-24T14:49:25.051125Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# retrieve dataframe dataset\nbase_path = '../input/handwriting-recognition'\n\ndef get_image_paths_and_labels(df, status):\n    paths = []\n    corrected_samples = []\n    data_path = os.path.join(base_path, status+'_v2', status)\n    fn=df['FILENAME'].to_numpy()\n    label=df['IDENTITY'].to_numpy()\n    \n    for i in range (len(fn)):\n        img_path = os.path.join(\n            data_path, fn[i]\n        )\n        if os.path.getsize(img_path):\n            paths.append(img_path)\n            corrected_samples.append(label[i])\n            \n    return paths, corrected_samples","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:25.057615Z","iopub.execute_input":"2022-07-24T14:49:25.057937Z","iopub.status.idle":"2022-07-24T14:49:25.066598Z","shell.execute_reply.started":"2022-07-24T14:49:25.057912Z","shell.execute_reply":"2022-07-24T14:49:25.065617Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_img_paths, train_labels = get_image_paths_and_labels(train, 'train')\nval_img_paths, val_labels = get_image_paths_and_labels(val, 'validation')\ntest_img_paths, test_labels = get_image_paths_and_labels(test, 'test')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:49:25.067953Z","iopub.execute_input":"2022-07-24T14:49:25.068722Z","iopub.status.idle":"2022-07-24T14:58:05.245107Z","shell.execute_reply.started":"2022-07-24T14:49:25.068686Z","shell.execute_reply":"2022-07-24T14:58:05.244094Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Get character\ncharacters = set()\n\nfor label in train_labels:\n    for char in label:\n        characters.add(char)\n\ncharacters = sorted(list(characters))\nprint(\"Vocab size: \", len(characters))\nprint(characters)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:05.248128Z","iopub.execute_input":"2022-07-24T14:58:05.249041Z","iopub.status.idle":"2022-07-24T14:58:05.336432Z","shell.execute_reply.started":"2022-07-24T14:58:05.249009Z","shell.execute_reply":"2022-07-24T14:58:05.335390Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Building character vocabulary\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Mapping characters to integers.\nchar_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n\n# Mapping integers back to original characters.\nnum_to_char = StringLookup(\n    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:05.338001Z","iopub.execute_input":"2022-07-24T14:58:05.338375Z","iopub.status.idle":"2022-07-24T14:58:08.064302Z","shell.execute_reply.started":"2022-07-24T14:58:05.338340Z","shell.execute_reply":"2022-07-24T14:58:08.063330Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def distortion_free_resize(image, img_size):\n    w, h = img_size\n    image = tf.image.resize_with_pad(image, h, w)\n\n    # Check the amount of padding needed to be done.\n#     pad_height = h - tf.shape(image)[0]\n#     pad_width = w - tf.shape(image)[1]\n\n    image = tf.transpose(image, perm=[1, 0, 2])\n    image = tf.image.flip_left_right(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:08.065756Z","iopub.execute_input":"2022-07-24T14:58:08.066341Z","iopub.status.idle":"2022-07-24T14:58:08.072973Z","shell.execute_reply.started":"2022-07-24T14:58:08.066303Z","shell.execute_reply":"2022-07-24T14:58:08.072088Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\npadding_token = 99\nimage_width = 256\nimage_height = 64\nmax_len = 32\n\n\ndef preprocess_image(image_path, img_size=(image_width, image_height)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, 1)\n    image = distortion_free_resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n\ndef vectorize_label(label):\n    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n    length = tf.shape(label)[0]\n    pad_amount = max_len - length\n    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n    return label\n\n\ndef process_images_labels(image_path, label):\n    image = preprocess_image(image_path)\n    label = vectorize_label(label)\n    return {\"image\": image, \"label\": label}\n\n\ndef prepare_dataset(image_paths, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n        process_images_labels, num_parallel_calls=AUTOTUNE\n    )\n    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:08.075425Z","iopub.execute_input":"2022-07-24T14:58:08.076213Z","iopub.status.idle":"2022-07-24T14:58:08.086912Z","shell.execute_reply.started":"2022-07-24T14:58:08.076143Z","shell.execute_reply":"2022-07-24T14:58:08.085946Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_ds = prepare_dataset(train_img_paths, train_labels)\nval_ds = prepare_dataset(val_img_paths, val_labels)\ntest_ds = prepare_dataset(test_img_paths, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:08.088344Z","iopub.execute_input":"2022-07-24T14:58:08.088866Z","iopub.status.idle":"2022-07-24T14:58:09.759166Z","shell.execute_reply.started":"2022-07-24T14:58:08.088834Z","shell.execute_reply":"2022-07-24T14:58:09.758194Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:09.760822Z","iopub.execute_input":"2022-07-24T14:58:09.761169Z","iopub.status.idle":"2022-07-24T14:58:09.769120Z","shell.execute_reply.started":"2022-07-24T14:58:09.761120Z","shell.execute_reply":"2022-07-24T14:58:09.768118Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for data in train_ds.take(1):\n    images, labels = data[\"image\"], data[\"label\"]\n\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    for i in range(16):\n        img = images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        # Gather indices where label!= padding_token.\n        label = labels[i]\n        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n        # Convert to string.\n        label = tf.strings.reduce_join(num_to_char(indices))\n        label = label.numpy().decode(\"utf-8\")\n\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(label)\n        ax[i // 4, i % 4].axis(\"off\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:09.770931Z","iopub.execute_input":"2022-07-24T14:58:09.771656Z","iopub.status.idle":"2022-07-24T14:58:10.950668Z","shell.execute_reply.started":"2022-07-24T14:58:09.771621Z","shell.execute_reply":"2022-07-24T14:58:10.949602Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class CTCLayer(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        # At test time, just return the computed predictions.\n        return y_pred\n\n\ndef build_model():\n    # Inputs to the model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First conv block.\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # Second conv block.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # We have used two max pool with pool size and strides 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing the output to the RNN part of the model.\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n\n    # RNNs.\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.2)\n    )(x)\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    # +2 is to account for the two special tokens introduced by the CTC loss.\n    # The recommendation comes here: https://git.io/J0eXP.\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    # Add CTC layer for calculating CTC loss at each step.\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    # Define the model.\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    # Optimizer.\n    opt = keras.optimizers.SGD(learning_rate=0.002,\n                               decay=1e-6,\n                               momentum=0.9,\n                               nesterov=True,\n                               clipnorm=5)\n    # Compile the model and return.\n    model.compile(optimizer=opt)\n    return model\n\n\n# Get the model.\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:10.951904Z","iopub.execute_input":"2022-07-24T14:58:10.952295Z","iopub.status.idle":"2022-07-24T14:58:12.030819Z","shell.execute_reply.started":"2022-07-24T14:58:10.952254Z","shell.execute_reply":"2022-07-24T14:58:12.029848Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"val_images = []\nval_labels = []\n\nfor batch in val_ds:\n    val_images.append(batch[\"image\"])\n    val_labels.append(batch[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:12.032319Z","iopub.execute_input":"2022-07-24T14:58:12.032889Z","iopub.status.idle":"2022-07-24T14:58:47.748556Z","shell.execute_reply.started":"2022-07-24T14:58:12.032851Z","shell.execute_reply":"2022-07-24T14:58:47.747554Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# val_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:47.750349Z","iopub.execute_input":"2022-07-24T14:58:47.750672Z","iopub.status.idle":"2022-07-24T14:58:47.758797Z","shell.execute_reply.started":"2022-07-24T14:58:47.750645Z","shell.execute_reply":"2022-07-24T14:58:47.757873Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def calculate_edit_distance(labels, predictions):\n    # Get a single batch and convert its labels to sparse tensors.\n    sparse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n\n    # Make predictions and convert them to sparse tensors.\n    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n    predictions_decoded = keras.backend.ctc_decode(\n        predictions, input_length=input_len, greedy=True\n    )[0][0][:, :max_len]\n    sparse_predictions = tf.cast(\n        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n    )\n\n    # Compute individual edit distances and average them out.\n    edit_distances = tf.edit_distance(\n        sparse_predictions, sparse_labels, normalize=False\n    )\n    return tf.reduce_mean(edit_distances)\n\n\nclass EditDistanceCallback(keras.callbacks.Callback):\n    def __init__(self, pred_model):\n        super().__init__()\n        self.prediction_model = pred_model\n\n    def on_epoch_end(self, epoch, logs=None):\n        edit_distances = []\n\n        for i in range(len(val_images)):\n            labels = val_labels[i]\n            predictions = self.prediction_model.predict(val_images[i])\n            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n\n        print(\n            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:47.762377Z","iopub.execute_input":"2022-07-24T14:58:47.763076Z","iopub.status.idle":"2022-07-24T14:58:47.774261Z","shell.execute_reply.started":"2022-07-24T14:58:47.762955Z","shell.execute_reply":"2022-07-24T14:58:47.773118Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Add early stopping\nes = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                   patience=5,\n                                   restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:47.775909Z","iopub.execute_input":"2022-07-24T14:58:47.776306Z","iopub.status.idle":"2022-07-24T14:58:47.784433Z","shell.execute_reply.started":"2022-07-24T14:58:47.776270Z","shell.execute_reply":"2022-07-24T14:58:47.783419Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"epochs = 30  # To get good results this should be at least 50.\n\nmodel = build_model()\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model)\n\n# Train the model.\nif 'prediction_model_ocr.h5' not in os.listdir('./'):\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=epochs,\n        callbacks=[edit_distance_callback],\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-24T14:58:47.785562Z","iopub.execute_input":"2022-07-24T14:58:47.785819Z","iopub.status.idle":"2022-07-24T16:07:09.604134Z","shell.execute_reply.started":"2022-07-24T14:58:47.785797Z","shell.execute_reply":"2022-07-24T16:07:09.603118Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"if 'prediction_model_ocr.h5' not in os.listdir('./'):\n    prediction_model.save('prediction_model_ocr.h5')\n    #prediction_model=M.load_model('model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:11:24.924819Z","iopub.execute_input":"2022-07-24T16:11:24.925596Z","iopub.status.idle":"2022-07-24T16:11:24.933639Z","shell.execute_reply.started":"2022-07-24T16:11:24.925554Z","shell.execute_reply":"2022-07-24T16:11:24.932378Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# A utility function to decode the output of the network.\ndef decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search.\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results and get back the text.\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\n#  Let's check results on some test samples.\nfor batch in test_ds.take(1):\n    batch_images = batch[\"image\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:07:09.659997Z","iopub.execute_input":"2022-07-24T16:07:09.660549Z","iopub.status.idle":"2022-07-24T16:07:10.819948Z","shell.execute_reply.started":"2022-07-24T16:07:09.660509Z","shell.execute_reply":"2022-07-24T16:07:10.819045Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:09:21.807332Z","iopub.execute_input":"2022-07-24T16:09:21.808440Z","iopub.status.idle":"2022-07-24T16:09:21.813993Z","shell.execute_reply.started":"2022-07-24T16:09:21.808392Z","shell.execute_reply":"2022-07-24T16:09:21.813081Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 100\nfor batch in train_ds.take(number_of_batches):\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    train.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntrain_output = train[:batch_size*number_of_batches]\ntrain_output[\"CER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntrain_output[\"WER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(train_output)\nprint(\"CER_test_average: \", train_output[\"CER\"].mean())\nprint(\"WER_test_average: \", train_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:09:26.297530Z","iopub.execute_input":"2022-07-24T16:09:26.297880Z","iopub.status.idle":"2022-07-24T16:09:39.114060Z","shell.execute_reply.started":"2022-07-24T16:09:26.297850Z","shell.execute_reply":"2022-07-24T16:09:39.113099Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"val[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in val_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    val.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\nval_output = val[:batch_size*number_of_batches]\nval_output[\"CER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\nval_output[\"WER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(val_output)\nprint(\"CER_test_average: \", val_output[\"CER\"].mean())\nprint(\"WER_test_average: \", val_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:09:51.540988Z","iopub.execute_input":"2022-07-24T16:09:51.541925Z","iopub.status.idle":"2022-07-24T16:09:57.465669Z","shell.execute_reply.started":"2022-07-24T16:09:51.541887Z","shell.execute_reply":"2022-07-24T16:09:57.464647Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"test[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in test_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    test.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntest_output = test[:batch_size*number_of_batches]\ntest_output[\"CER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntest_output[\"WER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(test_output)\nprint(\"CER_test_average: \", test_output[\"CER\"].mean())\nprint(\"WER_test_average: \", test_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:09:57.467201Z","iopub.execute_input":"2022-07-24T16:09:57.467807Z","iopub.status.idle":"2022-07-24T16:10:10.742363Z","shell.execute_reply.started":"2022-07-24T16:09:57.467769Z","shell.execute_reply":"2022-07-24T16:10:10.741373Z"},"trusted":true},"execution_count":40,"outputs":[]}]}