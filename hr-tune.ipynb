{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastwer\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport cv2\n\nimport fastwer #for calculating CER & WER","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:23.905344Z","iopub.execute_input":"2022-07-30T08:52:23.906097Z","iopub.status.idle":"2022-07-30T08:52:54.450782Z","shell.execute_reply.started":"2022-07-30T08:52:23.906004Z","shell.execute_reply":"2022-07-30T08:52:54.449696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"np.random.seed(63)\ntf.random.set_seed(63)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:54.452652Z","iopub.execute_input":"2022-07-30T08:52:54.453239Z","iopub.status.idle":"2022-07-30T08:52:54.459585Z","shell.execute_reply.started":"2022-07-30T08:52:54.453208Z","shell.execute_reply":"2022-07-30T08:52:54.458636Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/handwriting-recognition/written_name_train_v2.csv')\nval=pd.read_csv('../input/handwriting-recognition/written_name_validation_v2.csv')\ntest=pd.read_csv('../input/handwriting-recognition/written_name_test_v2.csv')\n\ntrain.dropna(inplace=True)\ntrain.reset_index(drop=True, inplace=True)\ntest.dropna(inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.dropna(inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:54.461025Z","iopub.execute_input":"2022-07-30T08:52:54.461643Z","iopub.status.idle":"2022-07-30T08:52:55.056387Z","shell.execute_reply.started":"2022-07-30T08:52:54.461607Z","shell.execute_reply":"2022-07-30T08:52:55.055426Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train['Length']=train['IDENTITY'].apply(lambda x : len(str(x)))\nmax_name = 16\nmin_name = 2\ntrain21=train[train['Length']>max_name]\ntrain=train[train['Length']<=max_name]\ntrain=train[train['Length']>=min_name]\ntrain['IDENTITY']=train['IDENTITY'].str.upper()\n\nval['IDENTITY']=val['IDENTITY'].str.upper()\ntest['IDENTITY']=test['IDENTITY'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.059270Z","iopub.execute_input":"2022-07-30T08:52:55.059672Z","iopub.status.idle":"2022-07-30T08:52:55.573116Z","shell.execute_reply.started":"2022-07-30T08:52:55.059635Z","shell.execute_reply":"2022-07-30T08:52:55.572120Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train21","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.574757Z","iopub.execute_input":"2022-07-30T08:52:55.575114Z","iopub.status.idle":"2022-07-30T08:52:55.595759Z","shell.execute_reply.started":"2022-07-30T08:52:55.575077Z","shell.execute_reply":"2022-07-30T08:52:55.594900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train[train['IDENTITY'] == 'UNREADABLE']","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.597976Z","iopub.execute_input":"2022-07-30T08:52:55.598687Z","iopub.status.idle":"2022-07-30T08:52:55.657171Z","shell.execute_reply.started":"2022-07-30T08:52:55.598649Z","shell.execute_reply":"2022-07-30T08:52:55.656149Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = train.loc[(train['IDENTITY'] != 'UNREADABLE')]\nval = val.loc[(val['IDENTITY'] != 'UNREADABLE')]\n#test = train.loc[(train['IDENTITY'] != 'UNREADABLE')]","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.658933Z","iopub.execute_input":"2022-07-30T08:52:55.659328Z","iopub.status.idle":"2022-07-30T08:52:55.738704Z","shell.execute_reply.started":"2022-07-30T08:52:55.659291Z","shell.execute_reply":"2022-07-30T08:52:55.737747Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max_data_train = 100000\nmax_data_val = 10000\ntrain = train.iloc[:max_data_train]\nval = val.iloc[:max_data_val]","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.740139Z","iopub.execute_input":"2022-07-30T08:52:55.740744Z","iopub.status.idle":"2022-07-30T08:52:55.746402Z","shell.execute_reply.started":"2022-07-30T08:52:55.740706Z","shell.execute_reply":"2022-07-30T08:52:55.745485Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(f\"Total training samples: {train.shape[0]}\")\nprint(f\"Total validation samples: {val.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.747696Z","iopub.execute_input":"2022-07-30T08:52:55.748687Z","iopub.status.idle":"2022-07-30T08:52:55.756134Z","shell.execute_reply.started":"2022-07-30T08:52:55.748651Z","shell.execute_reply":"2022-07-30T08:52:55.754969Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# retrieve dataframe dataset\nbase_path = '../input/handwriting-recognition'\n\ndef get_image_paths_and_labels(df, status):\n    paths = []\n    corrected_samples = []\n    data_path = os.path.join(base_path, status+'_v2', status)\n    fn=df['FILENAME'].to_numpy()\n    label=df['IDENTITY'].to_numpy()\n    \n    for i in range (len(fn)):\n        img_path = os.path.join(\n            data_path, fn[i]\n        )\n        if os.path.getsize(img_path):\n            paths.append(img_path)\n            corrected_samples.append(label[i])\n            \n    return paths, corrected_samples","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.761673Z","iopub.execute_input":"2022-07-30T08:52:55.761989Z","iopub.status.idle":"2022-07-30T08:52:55.770708Z","shell.execute_reply.started":"2022-07-30T08:52:55.761961Z","shell.execute_reply":"2022-07-30T08:52:55.769606Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_img_paths, train_labels = get_image_paths_and_labels(train, 'train')\nval_img_paths, val_labels = get_image_paths_and_labels(val, 'validation')\ntest_img_paths, test_labels = get_image_paths_and_labels(test, 'test')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T08:52:55.772325Z","iopub.execute_input":"2022-07-30T08:52:55.772836Z","iopub.status.idle":"2022-07-30T09:00:18.301707Z","shell.execute_reply.started":"2022-07-30T08:52:55.772801Z","shell.execute_reply":"2022-07-30T09:00:18.300406Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Get character\ncharacters = set()\n\nfor label in train_labels:\n    for char in label:\n        characters.add(char)\n\ncharacters = sorted(list(characters))\nprint(\"Vocab size: \", len(characters))\nprint(characters)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:18.303495Z","iopub.execute_input":"2022-07-30T09:00:18.304135Z","iopub.status.idle":"2022-07-30T09:00:18.421323Z","shell.execute_reply.started":"2022-07-30T09:00:18.304097Z","shell.execute_reply":"2022-07-30T09:00:18.420421Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Building character vocabulary\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Mapping characters to integers.\nchar_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n\n# Mapping integers back to original characters.\nnum_to_char = StringLookup(\n    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:18.422727Z","iopub.execute_input":"2022-07-30T09:00:18.423141Z","iopub.status.idle":"2022-07-30T09:00:20.861868Z","shell.execute_reply.started":"2022-07-30T09:00:18.423088Z","shell.execute_reply":"2022-07-30T09:00:20.860866Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def distortion_free_resize(image, img_size):\n    w, h = img_size\n    image = tf.image.resize_with_pad(image, h, w)\n\n    # Check the amount of padding needed to be done.\n#     pad_height = h - tf.shape(image)[0]\n#     pad_width = w - tf.shape(image)[1]\n\n    image = tf.transpose(image, perm=[1, 0, 2])\n    image = tf.image.flip_left_right(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:20.863279Z","iopub.execute_input":"2022-07-30T09:00:20.864009Z","iopub.status.idle":"2022-07-30T09:00:20.872449Z","shell.execute_reply.started":"2022-07-30T09:00:20.863969Z","shell.execute_reply":"2022-07-30T09:00:20.871274Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\npadding_token = 99\nimage_width = 256\nimage_height = 64\nmax_len = 32\n\n\ndef preprocess_image(image_path, img_size=(image_width, image_height)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, 1)\n    image = distortion_free_resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n\ndef vectorize_label(label):\n    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n    length = tf.shape(label)[0]\n    pad_amount = max_len - length\n    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n    return label\n\n\ndef process_images_labels(image_path, label):\n    image = preprocess_image(image_path)\n    label = vectorize_label(label)\n    return {\"image\": image, \"label\": label}\n\n\ndef prepare_dataset(image_paths, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n        process_images_labels, num_parallel_calls=AUTOTUNE\n    )\n    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:20.873840Z","iopub.execute_input":"2022-07-30T09:00:20.874646Z","iopub.status.idle":"2022-07-30T09:00:20.886419Z","shell.execute_reply.started":"2022-07-30T09:00:20.874602Z","shell.execute_reply":"2022-07-30T09:00:20.885420Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_ds = prepare_dataset(train_img_paths, train_labels)\nval_ds = prepare_dataset(val_img_paths, val_labels)\ntest_ds = prepare_dataset(test_img_paths, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:20.887709Z","iopub.execute_input":"2022-07-30T09:00:20.888126Z","iopub.status.idle":"2022-07-30T09:00:22.961492Z","shell.execute_reply.started":"2022-07-30T09:00:20.888091Z","shell.execute_reply":"2022-07-30T09:00:22.960507Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:22.962970Z","iopub.execute_input":"2022-07-30T09:00:22.963312Z","iopub.status.idle":"2022-07-30T09:00:22.971775Z","shell.execute_reply.started":"2022-07-30T09:00:22.963276Z","shell.execute_reply":"2022-07-30T09:00:22.970793Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for data in train_ds.take(1):\n    images, labels = data[\"image\"], data[\"label\"]\n\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    for i in range(16):\n        img = images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        # Gather indices where label!= padding_token.\n        label = labels[i]\n        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n        # Convert to string.\n        label = tf.strings.reduce_join(num_to_char(indices))\n        label = label.numpy().decode(\"utf-8\")\n\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(label)\n        ax[i // 4, i % 4].axis(\"off\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:22.973261Z","iopub.execute_input":"2022-07-30T09:00:22.974174Z","iopub.status.idle":"2022-07-30T09:00:24.227036Z","shell.execute_reply.started":"2022-07-30T09:00:22.974135Z","shell.execute_reply":"2022-07-30T09:00:24.226096Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CTCLayer(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        # At test time, just return the computed predictions.\n        return y_pred\n\n\ndef build_model_tune():\n    # Inputs to the model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First conv block.\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # Second conv block.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # We have used two max pool with pool size and strides 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing the output to the RNN part of the model.\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n\n    # RNNs.\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.2)\n    )(x)\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    # +2 is to account for the two special tokens introduced by the CTC loss.\n    # The recommendation comes here: https://git.io/J0eXP.\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    # Add CTC layer for calculating CTC loss at each step.\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    # Define the model.\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    \n    # Set the learning rate scheduler\n    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20))\n    \n    # Optimizer.\n    opt = keras.optimizers.SGD(learning_rate=0.002,\n                               decay=1e-6,\n                               momentum=0.9,\n                               nesterov=True,\n                               clipnorm=5)\n    # Compile the model and return.\n    model.compile(optimizer=opt)\n    return model\n\n\n# Get the model.\nmodel = build_model_tune()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:12:13.690626Z","iopub.execute_input":"2022-07-30T09:12:13.691058Z","iopub.status.idle":"2022-07-30T09:12:14.712943Z","shell.execute_reply.started":"2022-07-30T09:12:13.691007Z","shell.execute_reply":"2022-07-30T09:12:14.710969Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\ndef build_model():\n    # Inputs to the model\n    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n    labels = keras.layers.Input(name=\"label\", shape=(None,))\n\n    # First conv block.\n    x = keras.layers.Conv2D(\n        32,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv1\",\n    )(input_img)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # Second conv block.\n    x = keras.layers.Conv2D(\n        64,\n        (3, 3),\n        activation=\"relu\",\n        kernel_initializer=\"he_normal\",\n        padding=\"same\",\n        name=\"Conv2\",\n    )(x)\n    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n\n    # We have used two max pool with pool size and strides 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing the output to the RNN part of the model.\n    new_shape = ((image_width // 4), (image_height // 4) * 64)\n    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = keras.layers.Dropout(0.2)(x)\n\n    # RNNs.\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(128, return_sequences=True, dropout=0.2)\n    )(x)\n    x = keras.layers.Bidirectional(\n        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n    )(x)\n\n    # +2 is to account for the two special tokens introduced by the CTC loss.\n    # The recommendation comes here: https://git.io/J0eXP.\n    x = keras.layers.Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(x)\n\n    # Add CTC layer for calculating CTC loss at each step.\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    # Define the model.\n    model = keras.models.Model(\n        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    # Optimizer.\n    opt = keras.optimizers.SGD(learning_rate=0.002,\n                               decay=1e-6,\n                               momentum=0.9,\n                               nesterov=True,\n                               clipnorm=5)\n    # Compile the model and return.\n    model.compile(optimizer=opt)\n    return model\n\n\n# Get the model.\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:12:32.173598Z","iopub.execute_input":"2022-07-30T09:12:32.174122Z","iopub.status.idle":"2022-07-30T09:12:33.199749Z","shell.execute_reply.started":"2022-07-30T09:12:32.174085Z","shell.execute_reply":"2022-07-30T09:12:33.198742Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"val_images = []\nval_labels = []\n\nfor batch in val_ds:\n    val_images.append(batch[\"image\"])\n    val_labels.append(batch[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:12:37.016114Z","iopub.execute_input":"2022-07-30T09:12:37.016836Z","iopub.status.idle":"2022-07-30T09:13:08.551500Z","shell.execute_reply.started":"2022-07-30T09:12:37.016787Z","shell.execute_reply":"2022-07-30T09:13:08.550443Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# val_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:00:25.706169Z","iopub.status.idle":"2022-07-30T09:00:25.707308Z","shell.execute_reply.started":"2022-07-30T09:00:25.707050Z","shell.execute_reply":"2022-07-30T09:00:25.707073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_edit_distance(labels, predictions):\n    # Get a single batch and convert its labels to sparse tensors.\n    sparse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n\n    # Make predictions and convert them to sparse tensors.\n    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n    predictions_decoded = keras.backend.ctc_decode(\n        predictions, input_length=input_len, greedy=True\n    )[0][0][:, :max_len]\n    sparse_predictions = tf.cast(\n        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n    )\n\n    # Compute individual edit distances and average them out.\n    edit_distances = tf.edit_distance(\n        sparse_predictions, sparse_labels, normalize=False\n    )\n    return tf.reduce_mean(edit_distances)\n\n\nclass EditDistanceCallback(keras.callbacks.Callback):\n    def __init__(self, pred_model):\n        super().__init__()\n        self.prediction_model = pred_model\n\n    def on_epoch_end(self, epoch, logs=None):\n        edit_distances = []\n\n        for i in range(len(val_images)):\n            labels = val_labels[i]\n            predictions = self.prediction_model.predict(val_images[i])\n            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n\n        print(\n            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:13:08.584416Z","iopub.execute_input":"2022-07-30T09:13:08.584863Z","iopub.status.idle":"2022-07-30T09:13:08.597848Z","shell.execute_reply.started":"2022-07-30T09:13:08.584822Z","shell.execute_reply":"2022-07-30T09:13:08.596746Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Add early stopping\nes = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                   patience=5,\n                                   restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T09:13:08.599390Z","iopub.execute_input":"2022-07-30T09:13:08.599753Z","iopub.status.idle":"2022-07-30T09:13:08.608546Z","shell.execute_reply.started":"2022-07-30T09:13:08.599718Z","shell.execute_reply":"2022-07-30T09:13:08.607616Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"epochs = 30  # To get good results this should be at least 50.\n\nmodel = build_model()\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model)\n\n# Train the model.\nif 'prediction_model_ocr.h5' not in os.listdir('./'):\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=epochs,\n        callbacks=[edit_distance_callback],\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-30T10:22:44.736254Z","iopub.execute_input":"2022-07-30T10:22:44.736914Z","iopub.status.idle":"2022-07-30T11:32:17.054666Z","shell.execute_reply.started":"2022-07-30T10:22:44.736868Z","shell.execute_reply":"2022-07-30T11:32:17.053091Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"if 'prediction_model_ocr.h5' not in os.listdir('./'):\n    prediction_model.save('prediction_model_ocr.h5')\n    #prediction_model=M.load_model('model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:17.056889Z","iopub.execute_input":"2022-07-30T11:32:17.057426Z","iopub.status.idle":"2022-07-30T11:32:17.115659Z","shell.execute_reply.started":"2022-07-30T11:32:17.057352Z","shell.execute_reply":"2022-07-30T11:32:17.114408Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# A utility function to decode the output of the network.\ndef decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search.\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results and get back the text.\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\n#  Let's check results on some test samples.\nfor batch in test_ds.take(1):\n    batch_images = batch[\"image\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:17.120534Z","iopub.execute_input":"2022-07-30T11:32:17.120938Z","iopub.status.idle":"2022-07-30T11:32:18.673860Z","shell.execute_reply.started":"2022-07-30T11:32:17.120902Z","shell.execute_reply":"2022-07-30T11:32:18.672507Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:18.675541Z","iopub.execute_input":"2022-07-30T11:32:18.676201Z","iopub.status.idle":"2022-07-30T11:32:18.684026Z","shell.execute_reply.started":"2022-07-30T11:32:18.676156Z","shell.execute_reply":"2022-07-30T11:32:18.682584Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 100\nfor batch in train_ds.take(number_of_batches):\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    train.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntrain_output = train[:batch_size*number_of_batches]\ntrain_output[\"CER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntrain_output[\"WER\"] = train_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(train_output)\nprint(\"CER_test_average: \", train_output[\"CER\"].mean())\nprint(\"WER_test_average: \", train_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:18.686474Z","iopub.execute_input":"2022-07-30T11:32:18.687245Z","iopub.status.idle":"2022-07-30T11:32:34.591436Z","shell.execute_reply.started":"2022-07-30T11:32:18.687176Z","shell.execute_reply":"2022-07-30T11:32:34.590064Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"val[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in val_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    val.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\nval_output = val[:batch_size*number_of_batches]\nval_output[\"CER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\nval_output[\"WER\"] = val_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(val_output)\nprint(\"CER_test_average: \", val_output[\"CER\"].mean())\nprint(\"WER_test_average: \", val_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:34.593656Z","iopub.execute_input":"2022-07-30T11:32:34.594500Z","iopub.status.idle":"2022-07-30T11:32:42.012068Z","shell.execute_reply.started":"2022-07-30T11:32:34.594445Z","shell.execute_reply":"2022-07-30T11:32:42.009839Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test[\"PREDICTION\"] = \"\"\nprediksi = []\nstart = 0\nfinish = batch_size-1\nnumber_of_batches = 50\ni = 0\nfor batch in test_ds.take(number_of_batches):\n    finish = finish\n    batch_images = batch[\"image\"]\n    preds = prediction_model.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    test.loc[start:finish,\"PREDICTION\"] = pred_texts\n    start = start + len(pred_texts)\n    finish = finish + len(pred_texts)\ntest_output = test[:batch_size*number_of_batches]\ntest_output[\"CER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=True), axis = 1)\ntest_output[\"WER\"] = test_output.apply(lambda x: fastwer.score_sent(x[\"PREDICTION\"], x[\"IDENTITY\"], char_level=False), axis = 1)\ndisplay(test_output)\nprint(\"CER_test_average: \", test_output[\"CER\"].mean())\nprint(\"WER_test_average: \", test_output[\"WER\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-30T11:32:42.014749Z","iopub.execute_input":"2022-07-30T11:32:42.015227Z","iopub.status.idle":"2022-07-30T11:32:55.134224Z","shell.execute_reply.started":"2022-07-30T11:32:42.015177Z","shell.execute_reply":"2022-07-30T11:32:55.132968Z"},"trusted":true},"execution_count":35,"outputs":[]}]}